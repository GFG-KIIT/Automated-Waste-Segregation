{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f3ad20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imageio\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow.keras as K\n",
    "import tensorflow.keras.backend as Kback\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras.applications import vgg16\n",
    "from keras.applications import inception_v3\n",
    "from keras.src.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications import DenseNet121, NASNetMobile, EfficientNetB0, Xception\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.applications.densenet import DenseNet121\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c727717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile \n",
    "\n",
    "# Replace the path to your zip file and the directory where you want to extract the contents\n",
    "zip_file_path = r\"C:\\Users\\KIIT\\Downloads\\waste segregation\\waste_classification_data.zip\"\n",
    "extracted_dir = r\"C:\\Users\\KIIT\\Downloads\\waste segregation\\extracted_data\"# Specify the directory where you want to extract\n",
    "\n",
    "# Create a zip object and extract the contents to the specified directory\n",
    "with ZipFile(zip_file_path, 'r') as zObject:\n",
    "    zObject.extractall(path=extracted_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb96a948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory not found: C:\\Users\\KIIT\\Desktop\\waste segregation\\extracted_data\\DATASET\\DATASET\\TRAIN\\O\n",
      "Directory not found: C:\\Users\\KIIT\\Desktop\\waste segregation\\extracted_data\\DATASET\\DATASET\\TRAIN\\R\n",
      "Class O: 0 images with shapes [] ...\n",
      "Class R: 0 images with shapes [] ...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Define the extracted directory (update this path as needed)\n",
    "train_dir = r\"C:\\Users\\KIIT\\Desktop\\waste segregation\\extracted_data\\DATASET\\DATASET\\TRAIN\"\n",
    "\n",
    "# Define class names (folder names)\n",
    "class_names = ['O','R']\n",
    "\n",
    "# Initialize dictionary to store class shapes\n",
    "class_shapes = {}\n",
    "\n",
    "# Iterate over each class and calculate the shape of images\n",
    "for class_name in class_names:\n",
    "    class_path = os.path.join(train_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        shapes = []\n",
    "        for file_name in os.listdir(class_path):\n",
    "            file_path = os.path.join(class_path, file_name)\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with Image.open(file_path) as img:\n",
    "                        shapes.append(img.size)  # img.size returns (width, height)\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not open {file_path}: {e}\")\n",
    "        class_shapes[class_name] = shapes\n",
    "    else:\n",
    "        class_shapes[class_name] = []\n",
    "        print(f\"Directory not found: {class_path}\")  # Debug print\n",
    "\n",
    "# Print the shape of images in each class\n",
    "for class_name, shapes in class_shapes.items():\n",
    "    print(f\"Class {class_name}: {len(shapes)} images with shapes {shapes[:5]} ...\")  # Print first 5 shapes for brevity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73fa4128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory not found: C:\\Users\\KIIT\\Desktop\\waste segregation1\\extracted_data\\DATASET\\DATASET\\TRAIN\\O\n",
      "Directory not found: C:\\Users\\KIIT\\Desktop\\waste segregation1\\extracted_data\\DATASET\\DATASET\\TRAIN\\R\n",
      "Image resizing completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# Define the extracted directory (update this path as needed)\n",
    "train_dir = r\"C:\\Users\\KIIT\\Desktop\\waste segregation1\\extracted_data\\DATASET\\DATASET\\TRAIN\"\n",
    "resized_dir_train =  r\"C:\\Users\\KIIT\\Desktop\\waste segregation1\\resized_dir1\\resized_dir 1.1\"\n",
    "\n",
    "# Create the new directory structure\n",
    "if not os.path.exists(resized_dir_train):\n",
    "    os.makedirs(resized_dir_train)\n",
    "\n",
    "# Define class names (folder names)\n",
    "class_names = ['O','R']\n",
    "\n",
    "# Define the target size\n",
    "target_size = (128, 128)\n",
    "\n",
    "# Resize images and save them to the new directory\n",
    "for class_name in class_names:\n",
    "    class_path = os.path.join(train_dir, class_name)\n",
    "    resized_class_path = os.path.join(resized_dir_train, class_name)\n",
    "    \n",
    "    if not os.path.exists(resized_class_path):\n",
    "        os.makedirs(resized_class_path)\n",
    "\n",
    "    if os.path.isdir(class_path):\n",
    "        for filename in os.listdir(class_path):\n",
    "            if filename.endswith('.jpeg') or filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "                file_path = os.path.join(class_path, filename)\n",
    "                img = cv2.imread(file_path)\n",
    "                if img is not None:\n",
    "                    resized_img = cv2.resize(img, target_size)\n",
    "                    output_path = os.path.join(resized_class_path, filename)\n",
    "                    cv2.imwrite(output_path, resized_img)\n",
    "                else:\n",
    "                    print(f\"Failed to load image: {file_path}\")\n",
    "    else:\n",
    "        print(f\"Directory not found: {class_path}\")\n",
    "\n",
    "print(\"Image resizing completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e144126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class O: 12565 images with shapes [(128, 128), (128, 128), (128, 128), (128, 128), (128, 128)] ...\n",
      "Class R: 9999 images with shapes [(128, 128), (128, 128), (128, 128), (128, 128), (128, 128)] ...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "resized_dir_train = r\"C:\\Users\\KIIT\\Downloads\\waste segregation\\resized_dir1\\resized_dir1.1\"\n",
    "# Define class names (folder names)\n",
    "class_names = ['O','R']\n",
    "\n",
    "# Initialize dictionary to store class shapes\n",
    "class_shapes = {}\n",
    "\n",
    "# Iterate over each class and calculate the shape of images\n",
    "for class_name in class_names:\n",
    "    class_path = os.path.join(resized_dir_train, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        shapes = []\n",
    "        for file_name in os.listdir(class_path):\n",
    "            file_path = os.path.join(class_path, file_name)\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with Image.open(file_path) as img:\n",
    "                        shapes.append(img.size)  # img.size returns (width, height)\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not open {file_path}: {e}\")\n",
    "        class_shapes[class_name] = shapes\n",
    "    else:\n",
    "        class_shapes[class_name] = []\n",
    "        print(f\"Directory not found: {class_path}\")  # Debug print\n",
    "\n",
    "# Print the shape of images in each class\n",
    "for class_name, shapes in class_shapes.items():\n",
    "    print(f\"Class {class_name}: {len(shapes)} images with shapes {shapes[:5]} ...\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a0df37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "# Load images and assign labels\n",
    "for label, class_name in enumerate(class_names):\n",
    "    class_path = os.path.join(resized_dir_train, class_name)\n",
    "    image_files = os.listdir(class_path)\n",
    "\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(class_path, image_file)\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_COLOR)  # Read as GBR\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) \n",
    "        img = img / 255.0  # Normalize pixel values (assuming 8-bit images)\n",
    "        train_images.append(img)\n",
    "        train_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0156e2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22564\n"
     ]
    }
   ],
   "source": [
    "print(len(train_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a75cf8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class O: 1401 images with shapes [(223, 227), (225, 225), (225, 225), (225, 225), (225, 225)] ...\n",
      "Class R: 1112 images with shapes [(240, 210), (225, 225), (225, 224), (225, 225), (225, 225)] ...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Define the extracted directory (update this path as needed)\n",
    "test_dir = r\"C:\\Users\\KIIT\\Downloads\\waste segregation\\extracted_data\\DATASET\\DATASET\\TEST\"\n",
    "\n",
    "# Define class names (folder names)\n",
    "class_names = ['O','R']\n",
    "\n",
    "# Initialize dictionary to store class shapes\n",
    "class_shapes = {}\n",
    "\n",
    "# Iterate over each class and calculate the shape of images\n",
    "for class_name in class_names:\n",
    "    class_path = os.path.join(test_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        shapes = []\n",
    "        for file_name in os.listdir(class_path):\n",
    "            file_path = os.path.join(class_path, file_name)\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with Image.open(file_path) as img:\n",
    "                        shapes.append(img.size)  # img.size returns (width, height)\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not open {file_path}: {e}\")\n",
    "        class_shapes[class_name] = shapes\n",
    "    else:\n",
    "        class_shapes[class_name] = []\n",
    "        print(f\"Directory not found: {class_path}\")  # Debug print\n",
    "\n",
    "# Print the shape of images in each class\n",
    "for class_name, shapes in class_shapes.items():\n",
    "    print(f\"Class {class_name}: {len(shapes)} images with shapes {shapes[:5]} ...\")  # Print first 5 shapes for brevity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d58731ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image resizing completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# Define the extracted directory (update this path as needed)\n",
    "test_dir = r\"C:\\Users\\KIIT\\Downloads\\waste segregation\\extracted_data\\DATASET\\DATASET\\TEST\"\n",
    "resized_dir_test = r\"C:\\Users\\KIIT\\Downloads\\waste segregation\\resized_dir1\\resized_dir1.2\"\n",
    "# Create the new directory structure\n",
    "if not os.path.exists(resized_dir_test):\n",
    "    os.makedirs(resized_dir_test)\n",
    "\n",
    "# Define class names (folder names)\n",
    "class_names = ['O','R']\n",
    "\n",
    "# Define the target size\n",
    "target_size = (128, 128)\n",
    "\n",
    "# Resize images and save them to the new directory\n",
    "for class_name in class_names:\n",
    "    class_path = os.path.join(test_dir, class_name)\n",
    "    resized_class_path = os.path.join(resized_dir_test, class_name)\n",
    "    \n",
    "    if not os.path.exists(resized_class_path):\n",
    "        os.makedirs(resized_class_path)\n",
    "\n",
    "    if os.path.isdir(class_path):\n",
    "        for filename in os.listdir(class_path):\n",
    "            if filename.endswith('.jpeg') or filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "                file_path = os.path.join(class_path, filename)\n",
    "                img = cv2.imread(file_path)\n",
    "                if img is not None:\n",
    "                    resized_img = cv2.resize(img, target_size)\n",
    "                    output_path = os.path.join(resized_class_path, filename)\n",
    "                    cv2.imwrite(output_path, resized_img)\n",
    "                else:\n",
    "                    print(f\"Failed to load image: {file_path}\")\n",
    "    else:\n",
    "        print(f\"Directory not found: {class_path}\")\n",
    "\n",
    "print(\"Image resizing completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7b2b421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class O: 1401 images with shapes [(128, 128), (128, 128), (128, 128), (128, 128), (128, 128)] ...\n",
      "Class R: 1112 images with shapes [(128, 128), (128, 128), (128, 128), (128, 128), (128, 128)] ...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "resized_dir_test= r\"C:\\Users\\KIIT\\Downloads\\waste segregation\\resized_dir1\\resized_dir1.2\"\n",
    "\n",
    "# Define class names (folder names)\n",
    "class_names = ['O','R']\n",
    "\n",
    "# Initialize dictionary to store class shapes\n",
    "class_shapes = {}\n",
    "\n",
    "# Iterate over each class and calculate the shape of images\n",
    "for class_name in class_names:\n",
    "    class_path = os.path.join(resized_dir_test, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        shapes = []\n",
    "        for file_name in os.listdir(class_path):\n",
    "            file_path = os.path.join(class_path, file_name)\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with Image.open(file_path) as img:\n",
    "                        shapes.append(img.size)  # img.size returns (width, height)\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not open {file_path}: {e}\")\n",
    "        class_shapes[class_name] = shapes\n",
    "    else:\n",
    "        class_shapes[class_name] = []\n",
    "        print(f\"Directory not found: {class_path}\")  # Debug print\n",
    "\n",
    "# Print the shape of images in each class\n",
    "for class_name, shapes in class_shapes.items():\n",
    "    print(f\"Class {class_name}: {len(shapes)} images with shapes {shapes[:5]} ...\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1dc92cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "# Load images and assign labels\n",
    "for label, class_name in enumerate(class_names):\n",
    "    class_path = os.path.join(resized_dir_test, class_name)\n",
    "    image_files = os.listdir(class_path)\n",
    "\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(class_path, image_file)\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_COLOR)  # Read as GBR\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) \n",
    "        img = img / 255.0  # Normalize pixel values (assuming 8-bit images)\n",
    "        test_images.append(img)\n",
    "        test_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fe758ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2513\n"
     ]
    }
   ],
   "source": [
    "print(len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "301a1c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length: 22564\n",
      "labels counts: Counter({0: 12565, 1: 9999})\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels = shuffle(train_images, train_labels, random_state=42)\n",
    "\n",
    "print('Data length:', len(train_images))\n",
    "print('labels counts:', Counter(train_labels))\n",
    "\n",
    "train_images = np.array(train_images).reshape(-1, 128, 128, 3)\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c759db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length: 2513\n",
      "labels counts: Counter({0: 1401, 1: 1112})\n"
     ]
    }
   ],
   "source": [
    "test_images, test_labels = shuffle(test_images, test_labels, random_state=42)\n",
    "\n",
    "print('Data length:', len(test_images))\n",
    "print('labels counts:', Counter(test_labels))\n",
    "\n",
    "test_images = np.array(test_images).reshape(-1, 128, 128, 3)\n",
    "\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb288881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train length: 17553 (17553, 128, 128, 3)\n",
      "Validation length: 3762 (3762, 128, 128, 3)\n",
      "Test length: 3762 (3762, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Combine train and test data\n",
    "all_images = np.concatenate((train_images, test_images), axis=0)\n",
    "all_labels = np.concatenate((train_labels, test_labels), axis=0)\n",
    "\n",
    "# Split the combined data into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(all_images, all_labels, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Print the lengths and shapes of the datasets\n",
    "print('Train length:', len(X_train), X_train.shape)\n",
    "print('Validation length:', len(X_val), X_val.shape)\n",
    "print('Test length:', len(X_test), X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0083afa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "base_model = MobileNetV2(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(128,128,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05da25e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30b06b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(set(train_labels).union(set(test_labels)))\n",
    "Model_2 = Sequential()\n",
    "Model_2.add(base_model)\n",
    "Model_2.add(MaxPooling2D())\n",
    "Model_2.add(layers.Flatten())\n",
    "Model_2.add(layers.Dense(256, activation='relu'))\n",
    "Model_2.add(layers.Dense(128, activation='relu'))\n",
    "Model_2.add(layers.Dense(64, activation='relu'))\n",
    "Model_2.add(layers.Dense(NUM_CLASSES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "980041b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "losses = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "# Compile the model\n",
    "Model_2.compile(optimizer=optimizer, loss=losses, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f00fdefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_128 (Func  (None, 4, 4, 1280)        2257984   \n",
      " tional)                                                         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 2, 2, 1280)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5120)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               1310976   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3610242 (13.77 MB)\n",
      "Trainable params: 1352258 (5.16 MB)\n",
      "Non-trainable params: 2257984 (8.61 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21510ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "549/549 [==============================] - 294s 520ms/step - loss: 0.2479 - accuracy: 0.9053 - val_loss: 0.1689 - val_accuracy: 0.9335\n",
      "Epoch 2/20\n",
      "549/549 [==============================] - 267s 486ms/step - loss: 0.1517 - accuracy: 0.9413 - val_loss: 0.1851 - val_accuracy: 0.9234\n",
      "Epoch 3/20\n",
      "549/549 [==============================] - 280s 511ms/step - loss: 0.1194 - accuracy: 0.9561 - val_loss: 0.1721 - val_accuracy: 0.9330\n",
      "Epoch 4/20\n",
      "549/549 [==============================] - 315s 574ms/step - loss: 0.0832 - accuracy: 0.9680 - val_loss: 0.1875 - val_accuracy: 0.9362\n",
      "Epoch 5/20\n",
      "549/549 [==============================] - 283s 516ms/step - loss: 0.0580 - accuracy: 0.9778 - val_loss: 0.2135 - val_accuracy: 0.9365\n",
      "Epoch 6/20\n",
      "549/549 [==============================] - 281s 512ms/step - loss: 0.0435 - accuracy: 0.9843 - val_loss: 0.2729 - val_accuracy: 0.9192\n",
      "Epoch 7/20\n",
      "549/549 [==============================] - 291s 529ms/step - loss: 0.0337 - accuracy: 0.9880 - val_loss: 0.2783 - val_accuracy: 0.9397\n",
      "Epoch 8/20\n",
      "549/549 [==============================] - 243s 442ms/step - loss: 0.0263 - accuracy: 0.9903 - val_loss: 0.3038 - val_accuracy: 0.9306\n",
      "Epoch 9/20\n",
      "549/549 [==============================] - 167s 304ms/step - loss: 0.0231 - accuracy: 0.9918 - val_loss: 0.2926 - val_accuracy: 0.9320\n",
      "Epoch 10/20\n",
      "549/549 [==============================] - 272s 495ms/step - loss: 0.0204 - accuracy: 0.9931 - val_loss: 0.3156 - val_accuracy: 0.9333\n",
      "Epoch 11/20\n",
      "549/549 [==============================] - 258s 469ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.3702 - val_accuracy: 0.9378\n",
      "Epoch 12/20\n",
      "549/549 [==============================] - 256s 466ms/step - loss: 0.0161 - accuracy: 0.9941 - val_loss: 0.3708 - val_accuracy: 0.9351\n",
      "Epoch 13/20\n",
      "549/549 [==============================] - 268s 489ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.4069 - val_accuracy: 0.9391\n",
      "Epoch 14/20\n",
      "549/549 [==============================] - 257s 469ms/step - loss: 0.0130 - accuracy: 0.9967 - val_loss: 0.3432 - val_accuracy: 0.9394\n",
      "Epoch 15/20\n",
      "549/549 [==============================] - 246s 447ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.4152 - val_accuracy: 0.9304\n",
      "Epoch 16/20\n",
      "549/549 [==============================] - 285s 519ms/step - loss: 0.0144 - accuracy: 0.9949 - val_loss: 0.3925 - val_accuracy: 0.9309\n",
      "Epoch 17/20\n",
      "549/549 [==============================] - 266s 484ms/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 0.3827 - val_accuracy: 0.9357\n",
      "Epoch 18/20\n",
      "549/549 [==============================] - 306s 557ms/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 0.3308 - val_accuracy: 0.9285\n",
      "Epoch 19/20\n",
      "549/549 [==============================] - 318s 579ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.3989 - val_accuracy: 0.9306\n",
      "Epoch 20/20\n",
      "549/549 [==============================] - 325s 591ms/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.3250 - val_accuracy: 0.9341\n"
     ]
    }
   ],
   "source": [
    "history_Model_2 = Model_2.fit(X_train,y_train, epochs=20, batch_size=32,validation_data=(X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00dabd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 47s 399ms/step - loss: 0.3108 - accuracy: 0.9333\n",
      "Test Loss: 0.31076911091804504\n",
      "Test Accuracy: 0.9332801699638367\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = Model_2.evaluate(X_test,y_test)\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dc65e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
